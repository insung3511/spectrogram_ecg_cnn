{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래픽 카드 둘로 쓰기 (두개 있을때, 하나만 있다면 0)\n",
    "# gpu idx 를 0 또는 1 로 설정하시오\n",
    "import tensorflow as tf \n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # gpu idx\n",
    "\n",
    "tf.config.set_soft_device_placement(True)\n",
    "tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3893426443150310976\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14286848000\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7508377403646537647\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib \n",
    "import tensorflow as tf \n",
    "\n",
    "with tf.device('/device:GPU:1'):\n",
    "    print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로에 폴더가 없으면 폴더 만들기\n",
    "import os\n",
    "\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pathlib\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "EPOCH = 100\n",
    "KERNEL_SIZE = 3\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 256\n",
    "\n",
    "DATA_PATH = \"./spectrogram_plt/\"\n",
    "\n",
    "def list_to_list(input_list):\n",
    "    input_list_to_list = list(itertools.chain(*input_list))\n",
    "    return input_list_to_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrogram_plt\n",
      "105242\n"
     ]
    }
   ],
   "source": [
    "data_dir = pathlib.Path(DATA_PATH)\n",
    "print(data_dir)\n",
    "\n",
    "image_count = len(list(data_dir.glob('*/*.png')))\n",
    "print(image_count)\n",
    "\n",
    "f = list(data_dir.glob('F/*'))\n",
    "n = list(data_dir.glob('N/*'))\n",
    "q = list(data_dir.glob('Q/*'))\n",
    "s = list(data_dir.glob('S/*'))\n",
    "v = list(data_dir.glob('V/*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 split\n",
    "## train, test, validation data 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./spectrogram_plt/F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:06<00:00, 117.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./spectrogram_plt/N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85401/85401 [13:01<00:00, 109.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./spectrogram_plt/Q\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11039/11039 [01:54<00:00, 96.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./spectrogram_plt/S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1608/1608 [00:18<00:00, 86.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./spectrogram_plt/V\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6402/6402 [01:14<00:00, 86.32it/s]\n"
     ]
    }
   ],
   "source": [
    "parents_path = DATA_PATH\n",
    "child_path = os.listdir(parents_path)\n",
    "\n",
    "npy_check_list = []\n",
    "\n",
    "temp_converted_img = list()\n",
    "temp_ann_list = list()\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for pic_path in (child_path):\n",
    "    current_path = os.listdir(parents_path + pic_path)\n",
    "    print(\"[INFO] Current path : \" + parents_path + pic_path)\n",
    "    for file_name in tqdm(current_path):\n",
    "        path_for_array = parents_path + pic_path + \"/\" + file_name\n",
    "\n",
    "        img = cv2.imread(path_for_array)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_resize = cv2.resize(img, dsize=(128, 128), interpolation=cv2.INTER_AREA)\n",
    "        temp_converted_img.append(img_resize / 255.0)\n",
    "        \n",
    "        check_ann = pic_path\n",
    "        \n",
    "        if check_ann == \"N\":            # Normal\n",
    "            temp_ann_list.append([1, 0, 0, 0, 0])\n",
    "        \n",
    "        elif check_ann == \"S\":          # Supra-ventricular\n",
    "            temp_ann_list.append([0, 1, 0, 0, 0])\n",
    "        \n",
    "        elif check_ann == \"V\":          # Ventricular\n",
    "            temp_ann_list.append([0, 0, 1, 0, 0])\n",
    "        \n",
    "        elif check_ann == \"F\":          # False alarm\n",
    "            temp_ann_list.append([0, 0, 0, 1, 0])\n",
    "        \n",
    "        else:                           # Unclassed \n",
    "            temp_ann_list.append([0, 0, 0, 0, 1])\n",
    "    \n",
    "        y.append(temp_ann_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_y = np.array(temp_ann_list)\n",
    "temp_converted_img = np.array(temp_converted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SIZE]\t\tNpX lenght : (70512, 128, 128, 3)\n",
      "\t\tNpY length : (70512, 5)\n",
      "[SIZE]\t\tX_validation length : (11461, 128, 128, 3)\n",
      "\t\ty_validation length : (11461, 5)\n",
      "[SIZE]\t\tX_test length : (23269, 128, 128, 3)\n",
      "\t\ty_test length : (23269, 5)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(temp_converted_img, onehot_y, test_size=0.33, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "print(\"[SIZE]\\t\\tNpX lenght : {}\\n\\t\\tNpY length : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"[SIZE]\\t\\tX_validation length : {}\\n\\t\\ty_validation length : {}\".format(X_val.shape, y_val.shape))\n",
    "print(\"[SIZE]\\t\\tX_test length : {}\\n\\t\\ty_test length : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2160x864 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 랜덤으로 뽑아서 뿌려보기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(30, 12))\n",
    "plt.suptitle(\"random pal, per PAL\", fontsize=18)\n",
    "n = 0\n",
    "random.seed(11)\n",
    "for i in random.sample(range(6480), 16):\n",
    "    ax = plt.subplot(5, 5, n+1)\n",
    "    plt.imshow(temp_converted_img[i] * 255.0, interpolation='nearest')\n",
    "    ax.set_title(str(onehot_y[i]))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (128, 128, 1)\n",
    "\n",
    "models = keras.Sequential([\n",
    "    # tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_size),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Conv2D(128, kernel_size=(2, 2), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Conv2D(512, kernel_size=(2, 2), activation='relu'),\n",
    "    layers.MaxPool2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 126, 126, 64)      640       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 63, 63, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 62, 62, 128)       32896     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 31, 31, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 29, 29, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 14, 14, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 512)       524800    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 6, 6, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 18432)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              75501568  \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 20485     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 76,375,557\n",
      "Trainable params: 76,375,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.compile(\n",
    "        optimizer='adam',\n",
    "        # loss=\"sparse_categorical_crossentropy\",\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 콜백 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "outDir = './cheakpoint/lefms_model/' # 이 경로에 best 모델이 저장된다.\n",
    "model_names = outDir + 'weights-{val_accuracy:.4f}.h5'\n",
    "\n",
    "def get_callbacks(patience = 50): \n",
    "    with tf.device('/gpu:0'):\n",
    "        earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=patience)\n",
    "        model_checkpoint = ModelCheckpoint(model_names, monitor='val_accuracy', verbose=1, save_best_only=True, period = 1)\n",
    "    \n",
    "        # callbacks = [earlystop, model_checkpoint]     # earlystop 사용하고 싶으면 이거 풀고 아래꺼 주석 처리\n",
    "        callbacks = [model_checkpoint]\n",
    "        return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HILAB_~1\\AppData\\Local\\Temp/ipykernel_13296/1906611746.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/gpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     models_hist = models.fit(\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\HILAB_Labtop_02\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\HILAB_Labtop_02\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "callbacks = get_callbacks()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    models_hist = models.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        epochs=EPOCH,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks = [callbacks]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 시각화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 된 모델의 학습 과정 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_model__hist(hist):\n",
    "    path = './cheakpoint/lefms/' # loss, accuracy 그래프 저장할 path\n",
    "    createDirectory(path)\n",
    "\n",
    "    # loss 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "    plt.plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # accuracy 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "    plt.plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model__hist(models_hist)\n",
    "loss,acc = models.evaluate(X_val, y_val, verbose=2)\n",
    "print(\"multi_model의 정확도: {:5.2f}%\".format(100*acc))\n",
    "print(\"multi_model의 Loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러와서 confusion matrix 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "reconstructed_model = keras.models.load_model(\"./cheakpoint/lefms_model/weights-0.9868.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측값 얻기\n",
    "with tf.device('cpu:0'):\n",
    "    y_pred = reconstructed_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hat encoding 를 하나의 변수로 바꾸기\n",
    "new_y= []\n",
    "for val in y_test:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num:\n",
    "            max = num\n",
    "            cnt = idx + 1\n",
    "    new_y.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hat encoding 를 하나의 변수로 바꾸기\n",
    "new_y_pred = []\n",
    "for val in y_pred:\n",
    "    max = 0\n",
    "    cnt = 0\n",
    "    for idx, num in enumerate(val):\n",
    "        if max < num:\n",
    "            max = num\n",
    "            cnt = idx + 1\n",
    "    new_y_pred.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 정확도 산출\n",
    "with tf.device('/cpu:0'):\n",
    "    score = reconstructed_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('정답률 = ', score[1],'loss=', score[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusion matrix 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 개수 버전\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "cm2 = confusion_matrix(new_y, new_y_pred)\n",
    "sns.heatmap(cm2, annot = True, fmt = 'd', cmap= 'Reds')\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.yticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentile 버전\n",
    "total = np.sum(cm2, axis=1)\n",
    "cm2_percentile = cm2/total[:,None]\n",
    "sns.heatmap(np.round(cm2_percentile,3), annot = True, cmap= 'Reds')\n",
    "plt.xlabel('predict')\n",
    "plt.ylabel('real')\n",
    "plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.yticks([0.5, 1.5, 2.5, 3.5, 4.5], ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(new_y, new_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_report 그리기\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0 = N', '1 = S', '2 = V', '3 = F', '4 = Q']\n",
    "print(classification_report(new_y, new_y_pred, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c3cabcf2f29820bdd7faae982b59d335e0d215fb5382d93f3312fa3292e9b7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
