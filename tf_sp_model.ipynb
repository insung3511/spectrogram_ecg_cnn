{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import stft\n",
    "from scipy import signal\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "EPOCH = 100\n",
    "KERNEL_SIZE = 3\n",
    "BATCH_SIZE = 128\n",
    "IMAGE_HEIGHT = 512\n",
    "IMAGE_WIDTH = 512\n",
    "\n",
    "DATA_PATH = \"./mit_data/\"\n",
    "SAVE_PATH = \"./spectrogram_plt/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./spectrogram_plt/F\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 792/792 [00:08<00:00, 91.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Current path : ./spectrogram_plt/N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 43737/85401 [08:07<07:57, 87.27it/s] "
     ]
    }
   ],
   "source": [
    "parents_path = SAVE_PATH\n",
    "child_path = os.listdir(parents_path)\n",
    "\n",
    "npy_check_list = []\n",
    "\n",
    "temp_converted_img = list()\n",
    "temp_ann_list = list()\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "for pic_path in (child_path):\n",
    "    current_path = os.listdir(parents_path + pic_path)\n",
    "    print(\"[INFO] Current path : \" + parents_path + pic_path)\n",
    "    for file_name in tqdm(current_path):\n",
    "        path_for_array = parents_path + pic_path + \"/\" + file_name\n",
    "\n",
    "        img = cv2.imread(path_for_array)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img_resize = cv2.resize(img, dsize=(256, 256), interpolation=cv2.INTER_AREA)\n",
    "        temp_converted_img.append(img_resize / 255.0)\n",
    "        \n",
    "        check_ann = pic_path\n",
    "        \n",
    "        if check_ann == \"N\":            # Normal\n",
    "            temp_ann_list.append(0)\n",
    "        \n",
    "        elif check_ann == \"S\":          # Supra-ventricular\n",
    "            temp_ann_list.append(1)\n",
    "        \n",
    "        elif check_ann == \"V\":          # Ventricular\n",
    "            temp_ann_list.append(2)\n",
    "        \n",
    "        elif check_ann == \"F\":          # False alarm\n",
    "            temp_ann_list.append(3)\n",
    "        \n",
    "        else:                           # Unclassed \n",
    "            temp_ann_list.append(4)\n",
    "    \n",
    "        y.append(temp_ann_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로에 폴더가 없으면 폴더 만들기\n",
    "def createDirectory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_y = []\n",
    "for i in y:\n",
    "    if i == 0:\n",
    "        onehot_y.append([1,0,0,0,0])\n",
    "    elif i == 1:\n",
    "        onehot_y.append([0,1,0,0,0])\n",
    "    elif i == 2:\n",
    "        onehot_y.append([0,0,1,0,0])\n",
    "    elif i == 3:\n",
    "        onehot_y.append([0,0,0,1,0])\n",
    "    else:\n",
    "        onehot_y.append([0,0,0,0,1])\n",
    "\n",
    "onehot_y = np.array(onehot_y)\n",
    "temp_converted_img = np.array(temp_converted_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = temp_converted_img\n",
    "del X\n",
    "\n",
    "y = onehot_y\n",
    "del y\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=True)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.33, random_state=42, shuffle=True )\n",
    "\n",
    "print(\"[SIZE]\\t\\tNpX lenght : {}\\n\\t\\tNpY length : {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"[SIZE]\\t\\tX_validation length : {}\\n\\t\\ty_validation length : {}\".format(X_val.shape, y_val.shape))\n",
    "print(\"[SIZE]\\t\\tX_test length : {}\\n\\t\\ty_test length : {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize=(30, 12))\n",
    "plt.suptitle(\"GOD DAMN\", fontsize=18)\n",
    "n = 0\n",
    "random.seed(11)\n",
    "\n",
    "for i in random.sample(range(6480), 16):\n",
    "    ax = plt.subplot(5, 5, n+1)\n",
    "    plt.plot(X[i])\n",
    "    ax.set_title(str(y[i]))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (256, 256, 1)\n",
    "\n",
    "models = keras.Sequential([\n",
    "    layers.Conv2D(8, kernel_size=(4, 4), activation='relu', input_shape=input_size),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    layers.Conv2D(13, kernel_size=(2, 2), activation='relu', input_shape=input_size),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    layers.Conv2D(13, kernel_size=(2, 2), activation='relu', input_shape=input_size),\n",
    "    layers.MaxPool2D(pool_size=(2, 2)),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 콜백 설정\n",
    "outDir = './cheakpoint/lefms_model/' # 이 경로에 best 모델이 저장된다.\n",
    "model_names = outDir + 'weights-{val_accuracy:.4f}.h5'\n",
    "\n",
    "def get_callbacks(patience = 50):\n",
    "    earlystop = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=patience)\n",
    "    model_checkpoint = ModelCheckpoint(model_names, monitor='val_accuracy', verbose=1, save_best_only=True, period = 1)\n",
    "\n",
    "    callbacks = [model_checkpoint]\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "callbacks = get_callbacks()\n",
    "\n",
    "models_hist = models.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCH,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks = [callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 시각화 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 된 모델의 학습 과정 시각화\n",
    "def plot_model__hist(hist):\n",
    "    path = './cheakpoint/lefms/' # loss, accuracy 그래프 저장할 path\n",
    "    createDirectory(path)\n",
    "\n",
    "    # loss 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "    plt.plot(hist.history['val_loss'], color='r', label=\"Validation loss\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # accuracy 추이 그래프로 그려서 저장\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.plot(hist.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "    plt.plot(hist.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "    plt.savefig(path + 'model_loss_hist.png')\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model__hist(models_hist)\n",
    "loss,acc = models.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"multi_model의 정확도: {:5.2f}%\".format(100*acc))\n",
    "print(\"multi_model의 Loss: {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러와서 confusion matrix 그리기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c3cabcf2f29820bdd7faae982b59d335e0d215fb5382d93f3312fa3292e9b7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
